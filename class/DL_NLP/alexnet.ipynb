{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xEKX-jwTxjD",
        "outputId": "90b16fe7-c3b3-441f-8363-16b7acca74ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:03<00:00, 66.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------\n",
            "Using weight from the pretrained model from: https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\n",
            "----------------------------------------------------------------------\n",
            "weight: model[features.0.bias] <= pretrained_model[features.0.bias]\n",
            "weight: model[features.3.weight] <= pretrained_model[features.3.weight]\n",
            "weight: model[features.3.bias] <= pretrained_model[features.3.bias]\n",
            "weight: model[features.6.weight] <= pretrained_model[features.6.weight]\n",
            "weight: model[features.6.bias] <= pretrained_model[features.6.bias]\n",
            "weight: model[features.8.weight] <= pretrained_model[features.8.weight]\n",
            "weight: model[features.8.bias] <= pretrained_model[features.8.bias]\n",
            "weight: model[features.10.weight] <= pretrained_model[features.10.weight]\n",
            "weight: model[features.10.bias] <= pretrained_model[features.10.bias]\n",
            "weight: model[classifier.1.weight] <= pretrained_model[classifier.1.weight]\n",
            "weight: model[classifier.1.bias] <= pretrained_model[classifier.1.bias]\n",
            "weight: model[classifier.4.weight] <= pretrained_model[classifier.4.weight]\n",
            "weight: model[classifier.4.bias] <= pretrained_model[classifier.4.bias]\n",
            "weight: model[features.0.weight] <= pretrained_model[features.0.weight]\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Network architechture (num channels-1, num classes- 10) as follows:\n",
            "----------------------------------------------------------------------\n",
            "AlexNetR(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------------\n",
            "Network summary:\n",
            "----------------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]           7,808\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,029,322\n",
            "Trainable params: 57,029,322\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.20\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.55\n",
            "Estimated Total Size (MB): 226.23\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------------\n",
            "Network input output dims check\n",
            "----------------------------------------------------------------------\n",
            "input shape(batch_size x num_channels x height x width): torch.Size([5, 1, 227, 227])\n",
            "output shape(batch_size x num_classes): torch.Size([5, 10])\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Modification of https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from typing import Any, List, Dict\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    'AlexNet',\n",
        "    'AlexNetR',\n",
        "    'alexnet',\n",
        "]\n",
        "\n",
        "\n",
        "pretrained_model_urls = {\n",
        "    'alexnetr': 'https://download.pytorch.org/models/alexnet-owt-7be5be79.pth'\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Original AlexNet:\n",
        "    Input: image of size 3 x 227 x 227\n",
        "    Output: number class (1000-numbers)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_channels: int = 3,\n",
        "        num_classes: int = 1000\n",
        "    ) -> None:\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(6*6*256, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AlexNetR(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified AlexNet:\n",
        "    Input: image of size 3 x 227 x 227\n",
        "    Output: number class (1000-numbers)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_channels: int = 3,\n",
        "        num_classes: int = 10\n",
        "    ) -> None:\n",
        "        super(AlexNetR, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(6*6*256, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def alexnet(\n",
        "    net_type: str = 'revised',\n",
        "    flag_pretrained: bool = False,\n",
        "    flag_download_progress: bool = True,\n",
        "    idx_model_layer: List = [0],\n",
        "    idx_pretrained_model_layer: List = [0],\n",
        "    **kwargs: Any\n",
        ") ->AlexNetR:\n",
        "    \"\"\"Alexnet network architecture\n",
        "\n",
        "    Args:\n",
        "        net_type (str): alexnet varients ('original', 'revised')\n",
        "        flag_pretrained (bool): False - if \"True\" initialize with pre-trained model weights\n",
        "        flag_download_progress: True - progress bar will show during pre-trained model download\n",
        "        idx_model_layer (List): [0] - adjust 0-th layer's wights\n",
        "        idx_pretrained_model_layer (List): [0] - use 0-th layer's wights of pre-trained model to adjust the current model\n",
        "    \"\"\"\n",
        "    if net_type=='original':\n",
        "        model = AlexNet(**kwargs)\n",
        "    else:\n",
        "        model = AlexNetR(**kwargs)\n",
        "        if flag_pretrained:\n",
        "            dict_pretrained_state = load_state_dict_from_url(pretrained_model_urls['alexnetr'], progress=flag_download_progress)\n",
        "            print('-'*70)\n",
        "            print('Using weight from the pretrained model from: {}' .format(pretrained_model_urls['alexnetr']))\n",
        "            print('-'*70)\n",
        "            dict_model = weight_transform_layer_pos(model.state_dict(), dict_pretrained_state, idx_model_layer, idx_pretrained_model_layer)\n",
        "            print('-'*70)\n",
        "            model.load_state_dict(dict_model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def weight_transform_layer_pos(\n",
        "    dict_model: Dict[str, torch.Tensor],\n",
        "    dict_pretrained_state: Dict[str, torch.Tensor],\n",
        "    idx_model_layer: List[int] = [0],\n",
        "    idx_pretrained_model_layer: List[int] = [0]\n",
        ") ->Dict:\n",
        "    \"\"\"Weights update of the contom layers based on the pre-trained weights on ImageNet\n",
        "\n",
        "    Args:\n",
        "        dict_model (state-dict): new (custom) model weights state dict\n",
        "        dict_pretrained_state (state-dict): pretrained model weights state dict\n",
        "        idx_model_layer (list of intergers): index of the new (custom) model state dict want to change\n",
        "        idx_pretrained_model_layer (list of intergers): index of the pre-trained model state dict from where weights will be replaced\n",
        "    \"\"\"\n",
        "    # first copy all weights with same name and size\n",
        "    for k, v in dict_pretrained_state.items():\n",
        "        if k in dict_model:# matched weights name\n",
        "            if len(v.shape)==len(dict_model[k].shape):# matched weights size\n",
        "                dims_same = 1\n",
        "                for i in range(len(v.shape)):\n",
        "                    if v.shape[i]!=dict_model[k].shape[i]:\n",
        "                        dims_same = 0\n",
        "                if dims_same:\n",
        "                    print('weight: model[{}] <= pretrained_model[{}]' .format(k, k))\n",
        "                    dict_model[k] = v\n",
        "    # adjust the weights of the custom layers (by mean of the pretrained weights)\n",
        "    for idx in range(len(idx_model_layer)):\n",
        "        key_model = list(dict_model.keys())[idx_model_layer[idx]]\n",
        "        key_pretrained_model = list(dict_pretrained_state.keys())[idx_pretrained_model_layer[idx]]\n",
        "        print('weight: model[{}] <= pretrained_model[{}]' .format(key_model, key_pretrained_model))\n",
        "        w_org = dict_model[key_model]\n",
        "        w_trans = dict_pretrained_state[key_pretrained_model]\n",
        "\n",
        "        if w_org.shape[1] != w_trans.shape[1]:\n",
        "\n",
        "            w_trans = w_trans.mean(axis=1)\n",
        "            for i in range(w_org.shape[1]):\n",
        "                w_org[:,i,:,] = w_trans\n",
        "        dict_model[key_model] = w_org\n",
        "\n",
        "    return dict_model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    num_channels = 1\n",
        "    H, W = 227, 227\n",
        "    num_classes = 10\n",
        "    batch_size = 5\n",
        "    model = alexnet(flag_pretrained=True, num_channels=num_channels, num_classes=num_classes)\n",
        "\n",
        "    print('-'*70)\n",
        "    print('Network architechture (num channels-{}, num classes- {}) as follows:' .format(num_channels, num_classes))\n",
        "    print('-'*70)\n",
        "    print(model)\n",
        "    print('-'*70)\n",
        "\n",
        "    print('Network summary:')\n",
        "    print('-'*70)\n",
        "    summary(model, (num_channels, H, W, ), device=str(\"cpu\"))\n",
        "    print('-'*70)\n",
        "\n",
        "    print('Network input output dims check')\n",
        "    print('-'*70)\n",
        "    x = torch.randn(batch_size, num_channels, H, W)\n",
        "    y = model(x)\n",
        "    print('input shape(batch_size x num_channels x height x width): {}\\noutput shape(batch_size x num_classes): {}' .format(x.shape, y.shape))\n",
        "    print('-'*70)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJwDF08ETxjH",
        "outputId": "f08bbb29-27a3-4893-b47c-0256f06814f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(996.3445, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# just to check the pretrained weights loaded correctly or not!\n",
        "dict_model = model.state_dict()\n",
        "dict_pretrained_state = load_state_dict_from_url(pretrained_model_urls['alexnetr'], progress=True)\n",
        "\n",
        "dict_model = model.state_dict()\n",
        "idx = 'classifier.1.weight'\n",
        "idx = 'features.0.bias'\n",
        "idx = 'features.0.weight'\n",
        "\n",
        "T1 = torch.abs(dict_model[idx] - dict_pretrained_state[idx]).sum()\n",
        "\n",
        "print(T1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4YKNrqZTxjI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker 
[sudo] password for biswajit: 
sudo: docker: command not found
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker build -t test-image .\
> 
[+] Building 1.1s (1/1) FINISHED                                                                                                                                 docker:default
 => [internal] load build definition from Dockerfile                                                                                                                       0.4s
 => => transferring dockerfile: 2B                                                                                                                                         0.0s
ERROR: failed to solve: failed to read dockerfile: open Dockerfile: no such file or directory
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ ls
alexnet.ipynb  Assignment_1_b  Assignment_1d  Dockerfile.txt     group_project  paper                   work
Assignment_1   Assignment_1_c  books          grad_descnt.ipynb  image.jpg      pytorch_tutorial.ipynb
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker build -t test-image .\
> 
[+] Building 751.7s (12/12) FINISHED                                                                                                                             docker:default
 => [internal] load build definition from Dockerfile                                                                                                                       0.1s
 => => transferring dockerfile: 976B                                                                                                                                       0.0s
 => [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04                                                                                     4.5s
 => [internal] load .dockerignore                                                                                                                                          0.2s
 => => transferring context: 2B                                                                                                                                            0.0s
 => [1/8] FROM docker.io/nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04@sha256:7d3c22648869d206dc4fdd6a304ffd18309b7adeee1e43a1b53b5f126c44e69b                             240.2s
 => => resolve docker.io/nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04@sha256:7d3c22648869d206dc4fdd6a304ffd18309b7adeee1e43a1b53b5f126c44e69b                               0.3s
 => => sha256:7d3c22648869d206dc4fdd6a304ffd18309b7adeee1e43a1b53b5f126c44e69b 743B / 743B                                                                                 0.0s
 => => sha256:b3b0461d2469ba32ff4180f3c76a72ebc0acb5d024274b2dea3c352eaf433d73 2.84kB / 2.84kB                                                                             0.0s
 => => sha256:3d89d59a4dc16098d534f4ce440de814541e31a96aab0ae24aa286e8014696fe 18.85kB / 18.85kB                                                                           0.0s
 => => sha256:aece8493d3972efa43bfd4ee3cdba659c0f787f8f59c82fb3e48c87cbb22a12e 29.54MB / 29.54MB                                                                           1.2s
 => => sha256:45f7ea5367fe9dcee002e55e45a888af03a36523d11d2213ef9c6fc0088f6e96 4.62MB / 4.62MB                                                                             1.3s
 => => sha256:3d97a47c3c73a9f0e95e65070cfd89d749b89b490846c2a7ab0b796097d3c12b 55.73MB / 55.73MB                                                                           4.4s
 => => extracting sha256:aece8493d3972efa43bfd4ee3cdba659c0f787f8f59c82fb3e48c87cbb22a12e                                                                                  1.4s
 => => sha256:12cd4d19752f10fb4ec393dc915c62c18895ce0090f0db7773b2426f9059df16 185B / 185B                                                                                 1.8s
 => => sha256:da5a484f9d74b1673c155ea49073a322875f9a48118d0d5656c60224c7f8094e 6.89kB / 6.89kB                                                                             1.8s
 => => sha256:5e5846364eee50e93288b9e4085bc9e558ed543163636c9ca2e61a528cb4952d 1.29GB / 1.29GB                                                                            64.7s
 => => sha256:fd355de1d1f25492195368f3c3859f24af856e5d7a2ffb34951776daa50bd3e7 63.89kB / 63.89kB                                                                           3.4s
 => => extracting sha256:45f7ea5367fe9dcee002e55e45a888af03a36523d11d2213ef9c6fc0088f6e96                                                                                  0.3s
 => => sha256:3480bb79c6384806f3ae4d8854b5e7ea3e51c3e0ed913965790cdb1ac06cb0c4 1.69kB / 1.69kB                                                                             4.5s
 => => extracting sha256:3d97a47c3c73a9f0e95e65070cfd89d749b89b490846c2a7ab0b796097d3c12b                                                                                  2.0s
 => => sha256:e7016935dd60c632d835fe53b96c59b79194151f22ed555675a41525e066a99f 1.52kB / 1.52kB                                                                             5.6s
 => => sha256:99541166a1337295206d78a74f33e732d8acee77395b8e4de71f6d80c2dd951c 2.51GB / 2.51GB                                                                            96.7s
 => => sha256:8999112df5b031b628f484c1c2aec564d110232aa865626bf5be629955160ea1 88.43kB / 88.43kB                                                                           6.4s
 => => sha256:656f8da5a68b114e918e55693670f5e005682bf3f75a0cdab7abd60922183483 1.47GB / 1.47GB                                                                            48.8s
 => => extracting sha256:12cd4d19752f10fb4ec393dc915c62c18895ce0090f0db7773b2426f9059df16                                                                                  0.0s
 => => extracting sha256:da5a484f9d74b1673c155ea49073a322875f9a48118d0d5656c60224c7f8094e                                                                                  0.0s
 => => extracting sha256:5e5846364eee50e93288b9e4085bc9e558ed543163636c9ca2e61a528cb4952d                                                                                 20.7s
 => => extracting sha256:fd355de1d1f25492195368f3c3859f24af856e5d7a2ffb34951776daa50bd3e7                                                                                  0.0s
 => => extracting sha256:3480bb79c6384806f3ae4d8854b5e7ea3e51c3e0ed913965790cdb1ac06cb0c4                                                                                  0.0s
 => => extracting sha256:e7016935dd60c632d835fe53b96c59b79194151f22ed555675a41525e066a99f                                                                                  0.0s
 => => extracting sha256:99541166a1337295206d78a74f33e732d8acee77395b8e4de71f6d80c2dd951c                                                                                 96.9s
 => => extracting sha256:8999112df5b031b628f484c1c2aec564d110232aa865626bf5be629955160ea1                                                                                  0.0s
 => => extracting sha256:656f8da5a68b114e918e55693670f5e005682bf3f75a0cdab7abd60922183483                                                                                 42.5s
 => [2/8] RUN echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections                                                                               5.1s
 => [3/8] RUN DEBIAN_FRONTEND=noninteractive apt-get update && apt-get upgrade -y                                                                                        277.6s
 => [4/8] RUN apt-get install -y curl python3.10 python3.10-dev python3.10-distutils                                                                                      21.6s
 => [5/8] RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1                                                                                   1.5s
 => [6/8] RUN update-alternatives --set python /usr/bin/python3.10                                                                                                         1.6s
 => [7/8] RUN curl -s https://bootstrap.pypa.io/get-pip.py -o get-pip.py &&     python get-pip.py --force-reinstall &&     rm get-pip.py                                   7.8s
 => [8/8] RUN pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121                                          135.0s
 => exporting to image                                                                                                                                                    55.2s
 => => exporting layers                                                                                                                                                   54.9s
 => => writing image sha256:79f48fad7ccda038a8cf78c0bedc8334f3426f82df3d44c4abcb3732fb4dd4e3                                                                               0.0s
 => => naming to docker.io/library/test-image                                                                                                                              0.1s
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker

Usage:  docker [OPTIONS] COMMAND

A self-sufficient runtime for containers

Common Commands:
  run         Create and run a new container from an image
  exec        Execute a command in a running container
  ps          List containers
  build       Build an image from a Dockerfile
  pull        Download an image from a registry
  push        Upload an image to a registry
  images      List images
  login       Authenticate to a registry
  logout      Log out from a registry
  search      Search Docker Hub for images
  version     Show the Docker version information
  info        Display system-wide information

Management Commands:
  builder     Manage builds
  buildx*     Docker Buildx
  compose*    Docker Compose
  container   Manage containers
  context     Manage contexts
  image       Manage images
  manifest    Manage Docker image manifests and manifest lists
  network     Manage networks
  plugin      Manage plugins
  system      Manage Docker
  trust       Manage trust on Docker images
  volume      Manage volumes

Swarm Commands:
  swarm       Manage Swarm

Commands:
  attach      Attach local standard input, output, and error streams to a running container
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  events      Get real time events from the server
  export      Export a container's filesystem as a tar archive
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Return low-level information on Docker objects
  kill        Kill one or more running containers
  load        Load an image from a tar archive or STDIN
  logs        Fetch the logs of a container
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  rmi         Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  wait        Block until one or more containers stop, then print their exit codes

Global Options:
      --config string      Location of client config files (default "/root/.docker")
  -c, --context string     Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with "docker context use")
  -D, --debug              Enable debug mode
  -H, --host list          Daemon socket to connect to
  -l, --log-level string   Set the logging level ("debug", "info", "warn", "error", "fatal") (default "info")
      --tls                Use TLS; implied by --tlsverify
      --tlscacert string   Trust certs signed only by this CA (default "/root/.docker/ca.pem")
      --tlscert string     Path to TLS certificate file (default "/root/.docker/cert.pem")
      --tlskey string      Path to TLS key file (default "/root/.docker/key.pem")
      --tlsverify          Use TLS and verify the remote
  -v, --version            Print version information and quit

Run 'docker COMMAND --help' for more information on a command.

For more help on how to use Docker, head to https://docs.docker.com/go/guides/
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker ps -u 
unknown shorthand flag: 'u' in -u
See 'docker ps --help'.
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker ps -u
unknown shorthand flag: 'u' in -u
See 'docker ps --help'.
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker ps -a
CONTAINER ID   IMAGE         COMMAND    CREATED          STATUS                      PORTS     NAMES
77b14cdfee4d   hello-world   "/hello"   15 minutes ago   Exited (0) 15 minutes ago             reverent_einstein
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker start 77b14cdfee4d
77b14cdfee4d
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker attach 77b14cdfee4d
You cannot attach to a stopped container, start it first
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker start 77b14cdfee4d
77b14cdfee4d
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker attach 77b14cdfee4d
You cannot attach to a stopped container, start it first
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker ps -a 
CONTAINER ID   IMAGE         COMMAND    CREATED          STATUS                      PORTS     NAMES
77b14cdfee4d   hello-world   "/hello"   18 minutes ago   Exited (0) 42 seconds ago             reverent_einstein
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker run -v ~/Documents/RKMVERI_3RD/class/DL_NLP:/workspace --name test-run test-image bash

==========
== CUDA ==
==========

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.
   Use the NVIDIA Container Toolkit to start this container with GPU support; see
   https://docs.nvidia.com/datacenter/cloud-native/ .

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker ps -a 
CONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS                      PORTS     NAMES
244315d36b2d   test-image    "/opt/nvidia/nvidia_…"   25 seconds ago   Exited (0) 23 seconds ago             test-run
77b14cdfee4d   hello-world   "/hello"                 21 minutes ago   Exited (0) 4 minutes ago              reverent_einstein
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker rm 
"docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker rm 77b14cdfee4d
77b14cdfee4d
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker rm 244315d36b2d
244315d36b2d
(base) biswajit@arya16:~/Documents/RKMVERI_3RD/class/DL_NLP$ sudo docker run -it -v ~/Documents/RKMVERI_3RD/class/DL_NLP:/workspace --name test-run test-image bash 

==========
== CUDA ==
==========

CUDA Version 12.1.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.
   Use the NVIDIA Container Toolkit to start this container with GPU support; see
   https://docs.nvidia.com/datacenter/cloud-native/ .

*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md

root@f4df32b27d21:/# ls
NGC-DL-CONTAINER-LICENSE  bin  boot  cuda-keyring_1.0-1_all.deb  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  workspace
root@f4df32b27d21:/# cd workspace/
root@f4df32b27d21:/workspace# ls
Assignment_1  Assignment_1_b  Assignment_1_c  Assignment_1d  Dockerfile  alexnet.ipynb  books  grad_descnt.ipynb  group_project  image.jpg  paper  pytorch_tutorial.ipynb  work
root@f4df32b27d21:/workspace# ls
Assignment_1    Assignment_1_c  Dockerfile     books              group_project  mnist.py  pytorch_tutorial.ipynb
Assignment_1_b  Assignment_1d   alexnet.ipynb  grad_descnt.ipynb  image.jpg      paper     work
root@f4df32b27d21:/workspace# python mnist.py 
Traceback (most recent call last):
  File "/workspace/mnist.py", line 8, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'
root@f4df32b27d21:/workspace# pip install tqdm
Collecting tqdm
  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)
Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)
Installing collected packages: tqdm
Successfully installed tqdm-4.66.5
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
root@f4df32b27d21:/workspace# python mnist.py 
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:11<00:00, 873788.07it/s]
Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 118874.93it/s]
Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:07<00:00, 233016.62it/s]
Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Failed to download (trying next):
HTTP Error 403: Forbidden

Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz
Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 14871607.16it/s]
Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw

  0%|                                                                                                                                                             | 0/10 [00:00<?, ?it/s]Epoch:0 loss is 0.07091857492923737
 10%|██████████████▉                                                                                                                                      | 1/10 [00:40<06:02, 40.32s/it]Epoch:1 loss is 0.023116489872336388
 20%|█████████████████████████████▊                                                                                                                       | 2/10 [01:22<05:32, 41.62s/it]Epoch:2 loss is 0.012546641752123833
 30%|████████████████████████████████████████████▋                                                                                                        | 3/10 [02:03<04:48, 41.16s/it]Epoch:3 loss is 0.00858737900853157
 40%|███████████████████████████████████████████████████████████▌                                                                                         | 4/10 [02:42<04:02, 40.49s/it]Epoch:4 loss is 0.10841468721628189
 50%|██████████████████████████████████████████████████████████████████████████▌                                                                          | 5/10 [03:23<03:23, 40.67s/it]Epoch:5 loss is 0.06162044033408165
 60%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                           | 6/10 [04:05<02:44, 41.06s/it]Epoch:6 loss is 0.00011821577209047973
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                            | 7/10 [04:46<02:03, 41.03s/it]Epoch:7 loss is 0.011204369366168976
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                             | 8/10 [05:29<01:23, 41.51s/it]Epoch:8 loss is 8.451718713331502e-06
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 9/10 [06:10<00:41, 41.57s/it]Epoch:9 loss is 0.011772148311138153
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [06:51<00:00, 41.13s/it]
Predicted label: 9
root@f4df32b27d21:/workspace# python mnist.py 
Traceback (most recent call last):
  File "/workspace/mnist.py", line 17, in <module>
    from torchsummary import summary
ModuleNotFoundError: No module named 'torchsummary'
root@f4df32b27d21:/workspace# ^C
root@f4df32b27d21:/workspace# python mnist.py 
Traceback (most recent call last):
  File "/workspace/mnist.py", line 17, in <module>
    from torchsummary import summary
ModuleNotFoundError: No module named 'torchsummary'
root@f4df32b27d21:/workspace# pip install torchsummary
Collecting torchsummary
  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)
Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)
Installing collected packages: torchsummary
Successfully installed torchsummary-1.5.1
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
root@f4df32b27d21:/workspace# python mnist.py 
Downloading: "https://download.pytorch.org/models/alexnet-owt-7be5be79.pth" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 233M/233M [00:02<00:00, 82.2MB/s]
----------------------------------------------------------------------
Using weight from the pretrained model from: https://download.pytorch.org/models/alexnet-owt-7be5be79.pth
----------------------------------------------------------------------
weight: model[features.0.bias] <= pretrained_model[features.0.bias]
weight: model[features.3.weight] <= pretrained_model[features.3.weight]
weight: model[features.3.bias] <= pretrained_model[features.3.bias]
weight: model[features.6.weight] <= pretrained_model[features.6.weight]
weight: model[features.6.bias] <= pretrained_model[features.6.bias]
weight: model[features.8.weight] <= pretrained_model[features.8.weight]
weight: model[features.8.bias] <= pretrained_model[features.8.bias]
weight: model[features.10.weight] <= pretrained_model[features.10.weight]
weight: model[features.10.bias] <= pretrained_model[features.10.bias]
weight: model[classifier.1.weight] <= pretrained_model[classifier.1.weight]
weight: model[classifier.1.bias] <= pretrained_model[classifier.1.bias]
weight: model[classifier.4.weight] <= pretrained_model[classifier.4.weight]
weight: model[classifier.4.bias] <= pretrained_model[classifier.4.bias]
weight: model[features.0.weight] <= pretrained_model[features.0.weight]
----------------------------------------------------------------------
  0%|                                                                                                                                                             | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
  0%|                                                                                                                                                             | 0/10 [03:00<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/mnist.py", line 277, in <module>
    optimizer.zero_grad()  # Reset gradients
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 24, in inner
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 808, in zero_grad
    p.grad = None
KeyboardInterrupt

root@f4df32b27d21:/workspace# python mnist.py 
----------------------------------------------------------------------
Using weight from the pretrained model from: https://download.pytorch.org/models/alexnet-owt-7be5be79.pth
----------------------------------------------------------------------
weight: model[features.0.bias] <= pretrained_model[features.0.bias]
weight: model[features.3.weight] <= pretrained_model[features.3.weight]
weight: model[features.3.bias] <= pretrained_model[features.3.bias]
weight: model[features.6.weight] <= pretrained_model[features.6.weight]
weight: model[features.6.bias] <= pretrained_model[features.6.bias]
weight: model[features.8.weight] <= pretrained_model[features.8.weight]
weight: model[features.8.bias] <= pretrained_model[features.8.bias]
weight: model[features.10.weight] <= pretrained_model[features.10.weight]
weight: model[features.10.bias] <= pretrained_model[features.10.bias]
weight: model[classifier.1.weight] <= pretrained_model[classifier.1.weight]
weight: model[classifier.1.bias] <= pretrained_model[classifier.1.bias]
weight: model[classifier.4.weight] <= pretrained_model[classifier.4.weight]
weight: model[classifier.4.bias] <= pretrained_model[classifier.4.bias]
weight: model[features.0.weight] <= pretrained_model[features.0.weight]
----------------------------------------------------------------------
  0%|                                                                                                                                                             | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
  0%|                                                                                                                                                             | 0/10 [03:56<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/mnist.py", line 280, in <module>
    loss.backward()  # Backward pass
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt

root@f4df32b27d21:/workspace# python mnist.py 
----------------------------------------------------------------------
Using weight from the pretrained model from: https://download.pytorch.org/models/alexnet-owt-7be5be79.pth
----------------------------------------------------------------------
weight: model[features.0.bias] <= pretrained_model[features.0.bias]
weight: model[features.3.weight] <= pretrained_model[features.3.weight]
weight: model[features.3.bias] <= pretrained_model[features.3.bias]
weight: model[features.6.weight] <= pretrained_model[features.6.weight]
weight: model[features.6.bias] <= pretrained_model[features.6.bias]
weight: model[features.8.weight] <= pretrained_model[features.8.weight]
weight: model[features.8.bias] <= pretrained_model[features.8.bias]
weight: model[features.10.weight] <= pretrained_model[features.10.weight]
weight: model[features.10.bias] <= pretrained_model[features.10.bias]
weight: model[classifier.1.weight] <= pretrained_model[classifier.1.weight]
weight: model[classifier.1.bias] <= pretrained_model[classifier.1.bias]
weight: model[classifier.4.weight] <= pretrained_model[classifier.4.weight]
weight: model[classifier.4.bias] <= pretrained_model[classifier.4.bias]
weight: model[features.0.weight] <= pretrained_model[features.0.weight]
----------------------------------------------------------------------
  0%|                                                                                                                                                             | 0/10 [00:00<?, ?it/s]  0%|                                                                                                                                                             | 0/10 [05:45<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/mnist.py", line 278, in <module>
    outputs = classifier(images)  # Forward pass
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/mnist.py", line 123, in forward
    x = self.features(x)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py", line 488, in fn
    return if_false(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 791, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
KeyboardInterrupt
^C
root@f4df32b27d21:/workspace# ^C
root@f4df32b27d21:/workspace# python mnist.py 
  0%|                                                                                                                                                             | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
  0%|                                                                                                                                                             | 0/10 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/mnist.py", line 280, in <module>
    loss.backward()  # Backward pass
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
^C
root@f4df32b27d21:/workspace# python mnist.py
----------------------------------------------------------------------
Using weight from the pretrained model from: https://download.pytorch.org/models/alexnet-owt-7be5be79.pth
----------------------------------------------------------------------
weight: model[features.0.bias] <= pretrained_model[features.0.bias]
weight: model[features.3.weight] <= pretrained_model[features.3.weight]
weight: model[features.3.bias] <= pretrained_model[features.3.bias]
weight: model[features.6.weight] <= pretrained_model[features.6.weight]
weight: model[features.6.bias] <= pretrained_model[features.6.bias]
weight: model[features.8.weight] <= pretrained_model[features.8.weight]
weight: model[features.8.bias] <= pretrained_model[features.8.bias]
weight: model[features.10.weight] <= pretrained_model[features.10.weight]
weight: model[features.10.bias] <= pretrained_model[features.10.bias]
weight: model[classifier.1.weight] <= pretrained_model[classifier.1.weight]
weight: model[classifier.1.bias] <= pretrained_model[classifier.1.bias]
weight: model[classifier.4.weight] <= pretrained_model[classifier.4.weight]
weight: model[classifier.4.bias] <= pretrained_model[classifier.4.bias]
weight: model[features.0.weight] <= pretrained_model[features.0.weight]
----------------------------------------------------------------------
  0%|                                                                                                                                                             | 0/10 [00:00<?, ?it/s]                




  0%|                                                                                                                                                             | 0/10 [04:49<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/mnist.py", line 281, in <module>
    optimizer.step()  # Update weights
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 373, in wrapper
    out = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 163, in step
    adam(
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 311, in adam
    func(params,
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 432, in _single_tensor_adam
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt

root@f4df32b27d21:/workspace# 
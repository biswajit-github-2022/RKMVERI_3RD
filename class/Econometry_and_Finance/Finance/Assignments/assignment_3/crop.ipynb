{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: cropped\\ADANIPORTS.csv\n",
      "Processed and saved: cropped\\ASIANPAINT.csv\n",
      "Processed and saved: cropped\\AXISBANK.csv\n",
      "Processed and saved: cropped\\BAJAJ-AUTO.csv\n",
      "Processed and saved: cropped\\BAJAJFINSV.csv\n",
      "Processed and saved: cropped\\BAJFINANCE.csv\n",
      "Processed and saved: cropped\\BHARTIARTL.csv\n",
      "Processed and saved: cropped\\BPCL.csv\n",
      "Processed and saved: cropped\\BRITANNIA.csv\n",
      "Processed and saved: cropped\\CIPLA.csv\n",
      "Processed and saved: cropped\\COALINDIA.csv\n",
      "Processed and saved: cropped\\DRREDDY.csv\n",
      "Processed and saved: cropped\\EICHERMOT.csv\n",
      "Processed and saved: cropped\\GAIL.csv\n",
      "Processed and saved: cropped\\GRASIM.csv\n",
      "Processed and saved: cropped\\HCLTECH.csv\n",
      "Processed and saved: cropped\\HDFC.csv\n",
      "Processed and saved: cropped\\HDFCBANK.csv\n",
      "Processed and saved: cropped\\HEROMOTOCO.csv\n",
      "Processed and saved: cropped\\HINDALCO.csv\n",
      "Processed and saved: cropped\\HINDUNILVR.csv\n",
      "Processed and saved: cropped\\ICICIBANK.csv\n",
      "Processed and saved: cropped\\INDUSINDBK.csv\n",
      "Processed and saved: cropped\\INFY.csv\n",
      "Processed and saved: cropped\\IOC.csv\n",
      "Processed and saved: cropped\\ITC.csv\n",
      "Processed and saved: cropped\\JSWSTEEL.csv\n",
      "Processed and saved: cropped\\KOTAKBANK.csv\n",
      "Processed and saved: cropped\\LT.csv\n",
      "Processed and saved: cropped\\MARUTI.csv\n",
      "Processed and saved: cropped\\MM.csv\n",
      "Processed and saved: cropped\\NESTLEIND.csv\n",
      "Processed and saved: cropped\\NIFTY50_all.csv\n",
      "Processed and saved: cropped\\NTPC.csv\n",
      "Processed and saved: cropped\\ONGC.csv\n",
      "Processed and saved: cropped\\POWERGRID.csv\n",
      "Processed and saved: cropped\\RELIANCE.csv\n",
      "Processed and saved: cropped\\SBIN.csv\n",
      "Processed and saved: cropped\\SHREECEM.csv\n",
      "Processed and saved: cropped\\SUNPHARMA.csv\n",
      "Processed and saved: cropped\\TATAMOTORS.csv\n",
      "Processed and saved: cropped\\TATASTEEL.csv\n",
      "Processed and saved: cropped\\TCS.csv\n",
      "Processed and saved: cropped\\TECHM.csv\n",
      "Processed and saved: cropped\\TITAN.csv\n",
      "Processed and saved: cropped\\ULTRACEMCO.csv\n",
      "Processed and saved: cropped\\UPL.csv\n",
      "Processed and saved: cropped\\VEDL.csv\n",
      "Processed and saved: cropped\\WIPRO.csv\n",
      "Processed and saved: cropped\\ZEEL.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output directories\n",
    "input_directory = \"data\"  # Replace with your actual input directory\n",
    "output_directory = \"cropped\"  # Replace with your actual output directory\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Target date for filtering\n",
    "filter_date = pd.to_datetime('2019-04-30')\n",
    "\n",
    "# Iterate over each file in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Convert the \"Date\" column to datetime\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            # Filter the DataFrame for dates on or after '2019-04-30'\n",
    "            filtered_df = df[df['Date'] >= filter_date].loc[:, [\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "            \n",
    "            # Create a new file name for the output\n",
    "            output_file_path = os.path.join(output_directory, f\"{filename}\")\n",
    "            \n",
    "            # Save the filtered DataFrame to a new CSV file\n",
    "            filtered_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"Processed and saved: {output_file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Log any errors encountered during processing\n",
    "            print(f\"Error processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: return\\ADANIPORTS.csv\n",
      "Processed and saved: return\\ASIANPAINT.csv\n",
      "Processed and saved: return\\AXISBANK.csv\n",
      "Processed and saved: return\\BAJAJ-AUTO.csv\n",
      "Processed and saved: return\\BAJAJFINSV.csv\n",
      "Processed and saved: return\\BAJFINANCE.csv\n",
      "Processed and saved: return\\BHARTIARTL.csv\n",
      "Processed and saved: return\\BPCL.csv\n",
      "Processed and saved: return\\BRITANNIA.csv\n",
      "Processed and saved: return\\CIPLA.csv\n",
      "Processed and saved: return\\COALINDIA.csv\n",
      "Processed and saved: return\\DRREDDY.csv\n",
      "Processed and saved: return\\EICHERMOT.csv\n",
      "Processed and saved: return\\GAIL.csv\n",
      "Processed and saved: return\\GRASIM.csv\n",
      "Processed and saved: return\\HCLTECH.csv\n",
      "Processed and saved: return\\HDFC.csv\n",
      "Processed and saved: return\\HDFCBANK.csv\n",
      "Processed and saved: return\\HEROMOTOCO.csv\n",
      "Processed and saved: return\\HINDALCO.csv\n",
      "Processed and saved: return\\HINDUNILVR.csv\n",
      "Processed and saved: return\\ICICIBANK.csv\n",
      "Processed and saved: return\\INDUSINDBK.csv\n",
      "Processed and saved: return\\INFY.csv\n",
      "Processed and saved: return\\IOC.csv\n",
      "Processed and saved: return\\ITC.csv\n",
      "Processed and saved: return\\JSWSTEEL.csv\n",
      "Processed and saved: return\\KOTAKBANK.csv\n",
      "Processed and saved: return\\LT.csv\n",
      "Processed and saved: return\\MARUTI.csv\n",
      "Processed and saved: return\\MM.csv\n",
      "Processed and saved: return\\NESTLEIND.csv\n",
      "Processed and saved: return\\NIFTY50_all.csv\n",
      "Processed and saved: return\\NTPC.csv\n",
      "Processed and saved: return\\ONGC.csv\n",
      "Processed and saved: return\\POWERGRID.csv\n",
      "Processed and saved: return\\RELIANCE.csv\n",
      "Processed and saved: return\\SBIN.csv\n",
      "Processed and saved: return\\SHREECEM.csv\n",
      "Processed and saved: return\\SUNPHARMA.csv\n",
      "Processed and saved: return\\TATAMOTORS.csv\n",
      "Processed and saved: return\\TATASTEEL.csv\n",
      "Processed and saved: return\\TCS.csv\n",
      "Processed and saved: return\\TECHM.csv\n",
      "Processed and saved: return\\TITAN.csv\n",
      "Processed and saved: return\\ULTRACEMCO.csv\n",
      "Processed and saved: return\\UPL.csv\n",
      "Processed and saved: return\\VEDL.csv\n",
      "Processed and saved: return\\WIPRO.csv\n",
      "Processed and saved: return\\ZEEL.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories\n",
    "filtered_directory = \"cropped\"  # Replace with your actual filtered files directory\n",
    "output_directory = \"return\"      # Replace with your actual output directory\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to calculate \"Return\" and create a new CSV file\n",
    "def calculate_return(df):\n",
    "    # Sort the DataFrame by Date to ensure proper order\n",
    "    df = df.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "    # Calculate the \"Return\" as (current Close - previous Close) / previous Close\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "\n",
    "    # Keep only the \"Date\" and \"Return\" columns\n",
    "    return_df = df[['Date', 'Return']].dropna()\n",
    "\n",
    "    return return_df\n",
    "\n",
    "# Iterate over each filtered CSV file\n",
    "for filename in os.listdir(filtered_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(filtered_directory, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read the filtered CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Calculate the return and create a new DataFrame\n",
    "            return_df = calculate_return(df)\n",
    "            \n",
    "            # Create a new file name for the output\n",
    "            output_file_path = os.path.join(output_directory, f\"{filename}\")\n",
    "            \n",
    "            # Save the new DataFrame to a CSV file\n",
    "            return_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"Processed and saved: {output_file_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Log any errors encountered during processing\n",
    "            print(f\"Error processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADANIPORTS\n",
      "ASIANPAINT\n",
      "AXISBANK\n",
      "BAJAJ-AUTO\n",
      "BAJAJFINSV\n",
      "BAJFINANCE\n",
      "BHARTIARTL\n",
      "BPCL\n",
      "BRITANNIA\n",
      "CIPLA\n",
      "COALINDIA\n",
      "DRREDDY\n",
      "EICHERMOT\n",
      "GAIL\n",
      "GRASIM\n",
      "HCLTECH\n",
      "HDFC\n",
      "HDFCBANK\n",
      "HEROMOTOCO\n",
      "HINDALCO\n",
      "HINDUNILVR\n",
      "ICICIBANK\n",
      "INDUSINDBK\n",
      "INFY\n",
      "IOC\n",
      "ITC\n",
      "JSWSTEEL\n",
      "KOTAKBANK\n",
      "LT\n",
      "MARUTI\n",
      "MM\n",
      "NESTLEIND\n",
      "NIFTY50_all\n",
      "NTPC\n",
      "ONGC\n",
      "POWERGRID\n",
      "RELIANCE\n",
      "SBIN\n",
      "SHREECEM\n",
      "SUNPHARMA\n",
      "TATAMOTORS\n",
      "TATASTEEL\n",
      "TCS\n",
      "TECHM\n",
      "TITAN\n",
      "ULTRACEMCO\n",
      "UPL\n",
      "VEDL\n",
      "WIPRO\n",
      "ZEEL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing the files\n",
    "directory = \"return\"  # Replace with the actual directory path\n",
    "\n",
    "# List to store file names without extensions\n",
    "file_names = []\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if it's a file (not a directory)\n",
    "    if os.path.isfile(os.path.join(directory, filename)):\n",
    "        # Split the file name and extension, and store the file name without extension\n",
    "        name, _ = os.path.splitext(filename)\n",
    "        file_names.append(name)\n",
    "\n",
    "# Print the list of file names without extensions\n",
    "for name in file_names:\n",
    "    print(name)\n",
    "\n",
    "# file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADANIPORTS': (496, 2), 'ASIANPAINT': (496, 2), 'AXISBANK': (496, 2), 'BAJAJ-AUTO': (496, 2), 'BAJAJFINSV': (496, 2), 'BAJFINANCE': (496, 2), 'BHARTIARTL': (496, 2), 'BPCL': (496, 2), 'BRITANNIA': (496, 2), 'CIPLA': (496, 2), 'COALINDIA': (496, 2), 'DRREDDY': (496, 2), 'EICHERMOT': (496, 2), 'GAIL': (496, 2), 'GRASIM': (496, 2), 'HCLTECH': (496, 2), 'HDFC': (496, 2), 'HDFCBANK': (496, 2), 'HEROMOTOCO': (496, 2), 'HINDALCO': (496, 2), 'HINDUNILVR': (496, 2), 'ICICIBANK': (496, 2), 'INDUSINDBK': (496, 2), 'INFY': (496, 2), 'IOC': (496, 2), 'ITC': (496, 2), 'JSWSTEEL': (496, 2), 'KOTAKBANK': (496, 2), 'LT': (496, 2), 'MARUTI': (496, 2), 'MM': (496, 2), 'NESTLEIND': (496, 2), 'NIFTY50_all': (24352, 2), 'NTPC': (496, 2), 'ONGC': (496, 2), 'POWERGRID': (496, 2), 'RELIANCE': (496, 2), 'SBIN': (496, 2), 'SHREECEM': (496, 2), 'SUNPHARMA': (496, 2), 'TATAMOTORS': (496, 2), 'TATASTEEL': (496, 2), 'TCS': (496, 2), 'TECHM': (496, 2), 'TITAN': (496, 2), 'ULTRACEMCO': (496, 2), 'UPL': (496, 2), 'VEDL': (496, 2), 'WIPRO': (496, 2), 'ZEEL': (496, 2)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = \"return\"  # Replace with the actual directory path\n",
    "\n",
    "# Dictionary to store the shape of each DataFrame\n",
    "file_shapes = {}\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Get the file name without extension\n",
    "            file_name_without_ext = os.path.splitext(filename)[0]\n",
    "            \n",
    "            # Store the shape (rows, columns) of the DataFrame\n",
    "            file_shapes[file_name_without_ext] = df.shape\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Print the dictionary of file shapes\n",
    "print(file_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined DataFrame: (496, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the directory containing the CSV files\n",
    "input_directory = 'selected'  # Replace with your actual directory path\n",
    "\n",
    "# List all CSV files in the directory\n",
    "files = [f for f in os.listdir(input_directory) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize a list to store the \"Return\" columns\n",
    "return_columns = []\n",
    "\n",
    "# Loop through each file and extract the \"Return\" column\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_directory, file)\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if the \"Return\" column exists\n",
    "        if 'Return' in df.columns:\n",
    "            # Append the \"Return\" column to the list\n",
    "            return_columns.append(df[['Return']])\n",
    "        else:\n",
    "            print(f\"Warning: 'Return' column not found in {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Concatenate the \"Return\" columns horizontally\n",
    "combined_df = pd.concat(return_columns, axis=1)\n",
    "\n",
    "# Print the shape of the combined DataFrame\n",
    "print(f\"Shape of combined DataFrame: {combined_df.shape}\")\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file (optional)\n",
    "output_file = 'selected/combined_returns.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
